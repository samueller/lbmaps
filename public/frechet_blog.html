<script src="https://cdnjs.cloudflare.com/ajax/libs/svg.js/3.0.13/svg.min.js"></script>
<script src="https://sup.ai/js/util.js"></script>
<link href="https://unpkg.com/balloon-css/balloon.min.css" rel="stylesheet">
<link href="https://sup.ai/css/main.css" rel="stylesheet">
<link href="https://sup.ai/css/frechet.css" rel="stylesheet">
<meta name="viewport" content="width=device-width, initial-scale=1">
<p style="text-align: right;"><em><strong>Judea Pearl and Scott Mueller</strong></em></p>
<h2><strong>Visualization</strong></h2>
<div class="choose control">
    <label class="radio" for="conj-lower-bound"><strong>Conjunction</strong>:</label>
    <label class="radio" for="conj-lower-bound"><input id="conj-lower-bound" name="bound" value="0" type="radio"> Lower bounds</label> <span aria-label="Display minimum values of P(A, B) for each P(A) and P(B)" data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="conj-upper-bound"><input id="conj-upper-bound" name="bound" value="1" type="radio"> Upper bounds</label> <span aria-label="Display maximum values of P(A, B) for each P(A) and P(B)" data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="conj-combo-bound"><input id="conj-combo-bound" name="bound" value="2" type="radio"> Combined</label> <span aria-label="Display maximum values of P(A, B) for each P(A) and P(B) along with lines representing the lower bounds in order to see both lower and upper bounds together." data-balloon-length="large" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="conj-diff-bound"><input id="conj-diff-bound" name="bound" value="3" type="radio"> Range</label> <span aria-label="Display the range (maximum - minimum) of P(A, B) for each P(A) and P(B). Notice the range goes towards 0 further from the center. This means the bounds are tight near edges, when P(A) or P(B) is close to 0 or 1." data-balloon-length="large" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="conj-independent"><input id="conj-independent" name="bound" value="4" type="radio"> Independent</label> <span aria-label="Display P(A, B)'s exact values with the assumption that A and B are independent." data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
</div>
<div class="choose control">
    <label class="radio" for="disj-lower-bound"><strong>Disjunction</strong>:</label>
    <label class="radio" for="disj-lower-bound"><input id="disj-lower-bound" name="bound" value="5" type="radio"> Lower bounds</label> <span aria-label="Display minimum values of P(A ∨ B) for each P(A) and P(B)" data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="disj-upper-bound"><input id="disj-upper-bound" name="bound" value="6" type="radio"> Upper bounds</label> <span aria-label="Display maximum values of P(A ∨ B) for each P(A) and P(B)" data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="disj-combo-bound"><input id="disj-combo-bound" name="bound" value="7" type="radio"> Combined</label> <span aria-label="Display minimum values of P(A ∨ B) for each P(A) and P(B) along with lines representing the upper bounds in order to see both lower and upper bounds together." data-balloon-length="large" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="disj-diff-bound"><input id="disj-diff-bound" name="bound" value="8" type="radio"> Range</label> <span aria-label="Display the range (maximum - minimum) of P(A ∨ B) for each P(A) and P(B). Notice the range goes towards 0 further from the center. This means the bounds are tight near edges, when P(A) or P(B) is close to 0 or 1." data-balloon-length="large" data-balloon-pos="down">ⓘ</span>
    <label class="radio" for="disj-independent"><input id="disj-independent" name="bound" value="9" type="radio"> Independent</label> <span aria-label="Display P(A ∨ B)'s exact values with the assumption that A and B are independent." data-balloon-length="medium" data-balloon-pos="down">ⓘ</span>
</div>
<div id="plot">
    <div id="stats-window"></div>
</div>
<script src="https://sup.ai/js/frechet.js"></script>
<h2><strong>Introduction</strong></h2>
<p>Fréchet inequalities, also known as Boole-Fréchet inequalities, are among the earliest products of the probabilistic logic pioneered by George Boole and Augustus De Morgan in the 1850s, and formalized systematically by Maurice Fréchet (1935). In the simplest binary case these inequalities give us bounds on the probability P(A,B) of two joint events in terms of their marginals P(A) and P(B). The reason for revisiting these inequalities 84 years after their first publication is two-fold:
    <ul>
        <li>They play a major role in counterfactual reasoning (Ang and Pearl, 2019)</li>
        <li>We believe it will be illuminating for colleagues and students to see these probability bounds displayed using modern techniques of dynamic visualization</li>
    </ul>
</p>
<p>Fréchet bounds have wide application, including logic (Wagner, 2004), artificial intelligence (Wise and Henrion, 1985), statistics (Rüschendorf, 1991), quantum mechanics (Benavoli et al., 2016), and reliability theory (Collet, 1996). In counterfactual analysis, they come into focus when we have experimental results under treatment (X = x) as well as denial of treatment (X = x') and our interests lie in individuals who are responsive to treatment, namely those who will respond if exposed to treatment and will not respond under denial of treatment. Such individuals carry different names depending on the applications. They are called compliers, beneficiaries, respondents, gullibles, influenceable, persuadable, malleable, pliable, impressionable, susceptive, overtrusting, or dupable. And as the reader can figure out, the applications in marketing, sales, recruiting, product development, politics, and health science is enormous.</p>
<p>Although narrower bounds can be obtained when we have both observational and experimental data (Ang and Pearl, 2019; Tian and Pearl, 2000), Fréchet bounds are nevertheless informative when it comes to concluding responsiveness from experimental data alone.</p>

<h2><strong>Using the Plots</strong></h2>
<p>The plots visualize probability bounds of two events using logical conjunction, P(A,B), and logical disjunction, P(A∨B), with their marginals, P(A) and P(B), as axes on the unit square. Bounds for particular values of P(A) and P(B) can be seen by clicking on a type of bounds next to conjunction or disjunction and tracing the position on the plot to a color between blue and red. The color bar next to the plot indicates the probability. Clicking a different type of bounds animates the plot to demonstrate how the bounds changes. Hovering over or tapping on the plot reveals more information about the position being pointed at.</p>
<p>The gap between upper bounds and lower bounds gets vanishingly narrow near the edges of the unit square, which means that we can accurately determine the probability of the intersection given the probability of the marginal probabilities. The range plots make this very clear and they are the exact same plots for both P(A,B) and P(A∨B). Notice that the center holds the widest gaps. Every plot is symmetric around the P(B) = P(A) diagonal, this should be expected as P(A) and P(B) play interchangeable rolls in Fréchet inequalities.</p>

<h2><strong>Example 1</strong></h2>
<p>As guidance for using the plots let us take a simple example. Assume you measure the probabilities of your friends liking math and liking chocolate. Let A stand for the event that a friend picked at random likes math and B for the event that a friend picked at random likes chocolate. It turns out P(A) = 0.9 (almost all of your friends like math!) and P(B) = 0.3. You want to know the probability of a friend liking both math and chocolate, in other words you want to know P(A,B). If knowing whether a friend likes math doesn’t affect the probability they like chocolate, then events A and B are independent and we can get the exact value for P(A,B). This is a logical conjunction of A and B, so next to “Conjunction” above the plot, click on “Independent.” Hover over or tap on the location in the plot where the horizontal axis, P(A), is at 0.9 and the vertical axis, P(B), is at 0.3. You’ll see P(A,B) = 0.27 in the pop-up window.</p>
<p>However, maybe enjoying chocolate makes it more likely you’ll enjoy math. The caffeine in chocolate could have something to do with this. In this case, A and B are dependent and we may not be able to get an exact value for P(A,B) without more information. Click on “Combined” next to “Conjunction”. Now trace (0.9,0.3) again on the plot. You’ll see P(A,B) is between 0.2 and 0.3. Without knowing how dependent A and B are, we get fairly narrow bounds for the probability a friend likes both math and chocolate.</p>
        
<h2><strong>Example 2</strong></h2>
<p>Now let's take a more elaborate example, invoking counterfactual logic. Suppose we are conducting a marketing experiment and find 20% of customers will buy if shown advertisement 1, while 45% will buy if shown advertisement 2. We want to know how many customers will be swayed by advertisement 2 over advertisement 1. In other words, what percentage of customers buys if shown advertisement 2 and doesn’t buy when shown advertisement 1? To see this in the plot above, let A stand for the event that a customer won't buy when shown advertisement 1 and B for the event that a customer will buy when shown advertisement 2: P(A) = 100% - 20% = 80% = 0.8 and P(B) = 45% = 0.45. We want to find P(A,B). This joint probability is logical conjunction, so click on “Lower bounds” next to “Conjunction.” Tracing P(A) = 0.8 and P(B) = 0.45 lands in the middle of the blue strip corresponding to 0.2 to 0.3. This is the lower bounds, so P(A,B) ≥ 0.25. Now click on “Upper bounds” and trace again. You'll find P(A,B) ≤ 0.45. The “Combined” plot allows you to visualize both bounds at the same time. Hovering over or tapping on location (0.8,0.45) will display the complete bounds on any of the plots.</p>
<p>We might think that exactly 45% - 20% = 25% of customers were swayed by advertisement 2, but the plot shows us a range between 25% and 45%. This is because some people may buy if shown advertisement 1 and not buy if shown advertisement 2. As an example, if advertisement 2 convinces an entirely different segment of customers to buy than advertisement 1 does, then none of the 20% of customers who will buy after seeing advertisement 1 would buy if they had seen advertisement 2 instead. In this case, all 45% of the customers who will buy after seeing advertisement 2 are swayed by the advertisement.</p>
        
<h2><strong>Example 3</strong></h2>
<p>Let’s try another example involving counterfactual logic. Assume that we conduct a controlled randomized experiment (CRT) to evaluate the efficacy of some treatment X on survival Y, and find no effect whatsoever. For example, 10% of treated patients recovered, 90% died, and exactly the same proportions were found in the control group (those who were denied treatment), 10% recovered and 90% died.</p>
<p>Such treatment would no doubt be deemed ineffective by the FDA and other public policy makers. But health scientists and drug makers might be interested in knowing how the treatment affected individual patients: Did it have no effect on ANY individual or, perhaps, cured some and killed others. In the worst case, one can imagine a scenario where 10% of those who died under treatment would have been cured if not treated. Such a nightmarish scenario should surely be of grave concern to health scientists, not to mention patients who are seeking or using the treatment.</p>
<p>Let A stand for the event that patient John would die if given the treatment and B for the event that John would survive if denied treatment. The experimental data tells us that P(A) = 90% and P(B) = 10%. We are interested in the probability that John would die if treated and be cured if not treated, namely P(A,B).</p>
<p>Examining plot 1 we find that P(A,B), the probability that John is among those adversely reacting to the treatment is between zero and 10%. Quite an alarming finding, but not entirely unexpected considering the fact that randomized experiments deal with averages over populations and do not provide us information about an individual’s response. We may wish to ask what experimental results would assure John that he is not among the adversely affected. Examining the “Upper bound” plot we see that to guarantee a probability less than 5%, either P(A) or P(B) must be lower than 5%. This means that the mortality rate under either treatment or no-treatment should be lower than 5%.</p>        

<h2><strong>Inequalities</strong></h2>
<p>The Fréchet inequalities are:
    <ul>
        <li>max{0, P(A1) + P(A2) + … + P(An) − (n − 1)} ≤ P(A1,A2,…,An) ≤ min{P(A1), P(A2), …, P(An)}</li>
        <li>max{P(A1), P(A2), …, P(An)} ≤ P(A1∨A2∨…∨An) ≤ min{1, P(A1) + P(A2) + … + P(An)}</li>
    </ul>
</p>
<p>The binary cases of these inequalities used in the plots are:
    <ul>
        <li>max{0, P(A) + P(B) − 1} ≤ P(A,B) ≤ min{P(A), P(B)}</li>
        <li>max{P(A), P(B)} ≤ P(A∨B) ≤ min{1, P(A) + P(B)}</li>
    </ul>
</p>
<p>If events A and B are independent, then we can plot exact values:
    <ul>
        <li>P(A,B) = P(A)·P(B)</li>
        <li>P(A∨B) = P(A) + P(B) - P(A)·P(B)</li>
    </ul>
</p>

<h2><strong>Maurice Fréchet</strong></h2>
<p>Maurice Fréchet was a significant French mathematician with contributions to topology of point sets, metric spaces, statistics and probability, and calculus (Wikipedia Contributors, 2019). Fréchet published his proof for the above inequalities in the French journal Fundamenta Mathaticae in 1935 (Fréchet, 1935). During that time, he was Professor and Chair of Differential and Integral Calculus at the Sorbonne (Sack, 2016).</p>
<p>Jacques Fréchet, Maurice's father, was the head of a school in Paris (O’Connor and Robertson, 2019) while Maurice was young. Maurice then went to secondary school where he was taught math by the legendary French mathematician Jacques Hadamard. Hadamard would soon after become a professor at the University of Bordeaux. Eventually, Hadamard would become Fréchet's advisor for his doctorate. An educator like his father, Maurice was a schoolteacher in 1907, a lecturer in 1908, and then a professor in 1910 (Bru and Hertz, 2001). Probability research came later in his life. Unfortunately, his work wasn't always appreciated as the renowned Swedish mathematician Harald Cramér wrote (Bru and Hertz, 2001):</p>
<p>“In early years Fréchet had been an outstanding mathematician, doing pathbreaking work in functional analysis. He had taken up probabilistic work at a fairly advanced age, and I am bound to say that his work in this field did not seem very impressive to me.”</p>
<p>Nevertheless, Fréchet would go on to become very influential in probability and statistics. As a great response to Cramér's former criticism, an important bound is named after both Fréchet and Cramér, the Fréchet–Darmois–Cramér–Rao inequality (though more commonly known as Cramér–Rao bound)!</p>
        
<h2><strong>History</strong></h2>
<p>The reason Fréchet inequalities are also known as Boole-Fréchet inequalities is that George Boole published a proof of the conjunction version of the inequalities in his 1854 book An Investigation of the Laws of Thought (Boole, 1854). In chapter 19, Boole first showed the following:</p>
<blockquote>Major limit of n(xy) = least of values n(x) and n(y)<br>Minor limit of n(xy) = n(x) + n(y) - n(1).</blockquote>
<p>The terms n(xy), n(x), and n(y) are the number of occurrences of xy, x, and y, respectively. The term n(1) is the total number of occurrences. The reader can see that dividing all n-terms by n(1) yields the binary Fréchet inequalities for P(x,y). Boole then arrives at two general conclusions:</p>
<blockquote>&nbsp;&nbsp;&nbsp;&nbsp;1st. The major numerical limit of the class represented by any constituent will be found by prefixing n separately to each factor of the constituent, and taking the least of the resulting values.<br>&nbsp;&nbsp;&nbsp;&nbsp;2nd. The minor limit will be found by adding all the values above mentioned together, and subtracting from the result as many, less one, times the value of n(1).</blockquote>
<p>This result was an exercise that was part of an ambitious scheme which he describes in “Proposition IV” of chapter 17 as:</p>
<blockquote>Given the probabilities of any system of events; to determine by a general method the consequent or derived probability of any other event.</blockquote>
<p>We know now that Boole's task is super hard and, even today, we are not aware of any software that accomplishes his plan on any sizable number of events. The Boole-Fréchet inequalities are a tribute to his vision.</p>
<p>Boole's conjunction inequalities preceded Fréchet's by 81 years, so why aren't these known as Boole inequalities? One reason is Fréchet showed, for both conjunction and disjunction, that they are the narrowest possible bounds when only the marginal probabilities are known (Halperin, 1965).</p>
<p>Boole wrote a footnote in chapter 19 of his book that Augustus De Morgan, who was a collaborator of Boole's, first came up with the minor limit (lower bound) of the conjunction of two variables:</p>
<blockquote>the minor limit of nxy is applied by Professor De Morgan, by whom it appears to have been first given, to the syllogistic form:<br>&nbsp;&nbsp;&nbsp;&nbsp;Most men in a certain company have coats.<br>&nbsp;&nbsp;&nbsp;&nbsp;Most men in the same company have waistcoats.<br>&nbsp;&nbsp;&nbsp;&nbsp;Therefore some in the company have coats and waistcoats.</blockquote>
<p>De Morgan wrote about this syllogism in his 1859 paper “On the Syllogism, and On the Logic of Relations” (De Morgan, 1859). Boole and De Morgan became lifelong friends after Boole wrote to him in 1842 (Burris, 2010). Although De Morgan was Boole’s senior and published a book on probability in 1835 and on “Formal Logic” in 1847, he never reached Boole’s height in symbolic logic.</p>
<p>Predating Fréchet, Boole, and De Morgan is Charles Stanhope's Demonstrator logic machine, an actual physical device, that calculates binary Fréchet inequalities for both conjunction and disjunction. Robert Harley wrote an article in 1879 in Mind: A Quarterly Review of Psychology and Philosophy (Harley, 1879) that described Stanhope's instrument. In addition to several of these machines having been created, Stanhope had an unfinished manuscript of logic he wrote between 1800 and 1815 describing rules and construction of the machine for "discovering consequences in logic." In Stanhope's manuscript, he describes calculating the lower bound of conjunction with α, β, and μ, where α and β represent all, some, most, fewest, a number, or a definite ratio of part to whole (but not none), and μ is unity: "α + β - μ measures the extent of the consequence between A and B." This gives the "minor limit." Some examples are given by Harley. One of them is that some of 5 pictures hanging on the north side and some of 5 pictures are portraits tells us nothing about how many pictures are portraits hanging in the north. But if 3/5 are hanging in the north and 4/5 are portraits, then at least 3/5 + 4/5 - 1 = 2/5 are portraits on the north side. Similarly, with De Morgan's coats syllogism, "(most + most - all) men = some men" have both coats and waistcoats.</p>
<p>The Demonstrator logic machine works by sliding red transparent glass from the right over a separate gray wooden slide from the left. The overlapping portion will look dark red. The slides represent probabilities, P(A) and P(B), where sliding the entire distance of the middle square represents a probability of 1. The reader can verify that the dark red (overlap) is equivalent to the lower bound, P(A) + P(B) - 1. To find the "major limit," or upper bound, simply slide the red transparent glass from the left on top of the gray slide. Dark red will appear as the length of the shorter of the two slides, min{P(A), P(B)}!</p>
<h2><strong>References</strong></h2>
<p>Wikipedia Contributors, "Fréchet inequalities," <em>en.wikipedia.org</em>, para. 1, Aug. 4, 2019. [Online]. Available: <a href="https://en.wikipedia.org/wiki/Fréchet_inequalities">https://en.wikipedia.org/wiki/Fréchet_inequalities</a>. [Accessed Oct. 7, 2019].</p>
<p>Ang Li and Judea Pearl, "Unit Selection Based on Counterfactual Logic," UCLA Cognitive Systems Laboratory, Technical Report (R-488), June 2019. In <em>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)</em>, 1793-1799, 2019. [Online]. Available: <a href="http://ftp.cs.ucla.edu/pub/stat_ser/r488-reprint.pdf">http://ftp.cs.ucla.edu/pub/stat_ser/r488-reprint.pdf</a>. [Accessed Oct. 11, 2019].</p>
<p>Carl G. Wagner, "Modus tollens probabilized," <em>Journal for the Philosophy of Science</em>, vol. 55, pp. 747–753, 2004. [Online serial]. Available: <a href="http://www.math.utk.edu/~wagner/papers/2004.pdf">http://www.math.utk.edu/~wagner/papers/2004.pdf</a>. [Accessed Oct. 7, 2019].</p>
<p>Ben P. Wise and Max Henrion, "A Framework for Comparing Uncertain Inference Systems to Probability," In Proc. of the First Conference on Uncertainty in Artificial Intelligence (UAI1985), 1985. [Online]. Available: <a href="https://arxiv.org/abs/1304.3430">https://arxiv.org/abs/1304.3430</a>. [Accessed Oct. 7, 2019].</p>
<p>L. Rüschendorf, "Fréchet-bounds and their applications," <em>Advances in Probability Distributions with Given Marginals, Mathematics and Its Applications</em>, pp. 151–187, 1991. [Online]. Available: <a href="https://books.google.com/books?id=4uNCdVrrw2cC">https://books.google.com/books?id=4uNCdVrrw2cC</a>. [Accessed Oct. 7, 2019].</p>
<p>Alessio Benavoli, Alessandro Facchini, and Marco Zaffalon, "Quantum mechanics: The Bayesian theory generalised to the space of Hermitian matrices," <em>Physics Review A</em>, vol. 94, no. 4, pp. 1-26, Oct. 10, 2016. [Online]. Available: <a href="https://arxiv.org/abs/1605.08177">https://arxiv.org/abs/1605.08177</a>. [Accessed Oct. 7, 2019].</p>
<p>J. Collet, "Some remarks on rare-event approximation," <em>IEEE Transactions on Reliability</em>, vol. 45, no. 1, pp. 106-108, Mar 1996. [Online]. Available: <a href="https://ieeexplore.ieee.org/document/488924">https://ieeexplore.ieee.org/document/488924</a>. [Accessed Oct. 7, 2019].</p>
<p>Wikipedia Contributors, "Maurice René Fréchet," <em>en.wikipedia.org</em>, para. 1, Oct. 7, 2019. [Online]. Available: <a href="https://en.wikipedia.org/wiki/Maurice_René_Fréchet">https://en.wikipedia.org/wiki/Maurice_René_Fréchet</a>. [Accessed Oct. 7, 2019].</p>
<p>Maurice Fréchet, "Généralisations du théorème des probabilités totales," <em>Fundamenta Mathematicae</em>, vol. 25, no. 1, pp. 379–387, 1935. [Online]. Available: <a href="http://matwbn.icm.edu.pl/ksiazki/fm/fm25/fm25132.pdf">http://matwbn.icm.edu.pl/ksiazki/fm/fm25/fm25132.pdf</a>. [Accessed Oct. 7, 2019].</p>
<p>Harald Sack, "Maurice René Fréchet and the Theory of Abstract Spaces," <em>SciHi Blog</em>, Sept. 2016. [Online]. Available: <a href="http://scihi.org/maurice-rene-frechet/">http://scihi.org/maurice-rene-frechet/</a>. [Accessed Oct. 7, 2019].</p>
<p>J J O'Connor and E F Robertson, "René Maurice Fréchet," <em>MacTutor History of Mathematics archive</em>. [Online]. Available: <a href="http://www-groups.dcs.st-and.ac.uk/history/Biographies/Frechet.html">http://www-groups.dcs.st-and.ac.uk/history/Biographies/Frechet.html</a>. [Accessed Oct. 7, 2019].</p>
<p>B. Bru and S. Hertz, "Maurice Fréchet," <em>Statisticians of the Centuries</em>, pp. 331-334, Jan. 2001. [Online]. Available: <a href="https://books.google.com/books?id=6DD1FKq6fFoC&pg=PA331">https://books.google.com/books?id=6DD1FKq6fFoC&pg=PA331</a>. [Accessed Oct. 7, 2019].</p>
<p>"Fréchet, Maurice," <em>Encyclopedia of Mathematics</em>. [Online]. Available: <a href="https://www.encyclopediaofmath.org/index.php/Fr%C3%A9chet,_Maurice">https://www.encyclopediaofmath.org/index.php/Fr%C3%A9chet,_Maurice</a>. [Accessed Oct. 7, 2019].</p>
<p>George Boole, <em>An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities</em>, Cambridge: Macmillan and Co., 1854. [E-book] Available by Project Gutenberg: <a href="https://books.google.com/books?id=JBbkAAAAMAAJ&pg=PA201&lpg=PA201">https://books.google.com/books?id=JBbkAAAAMAAJ&pg=PA201&lpg=PA201</a>. [Accessed Oct. 11, 2019].</p>
<p>Theodore Hailperin, <em>The American Mathematical Monthly</em>, vol. 72, no. 4, pp. 343-359, April 1965. [Abstract]. Available: <a href="https://www.jstor.org/stable/2313491">https://www.jstor.org/stable/2313491</a>. [Accessed Oct. 11, 2019].</p>
<p>Augustus De Morgan, <em>On the Syllogism, and On the Logic of Relations</em>, 1859. Available: <a href="https://books.google.com/books?id=t02wDwAAQBAJ&pg=PA217">https://books.google.com/books?id=t02wDwAAQBAJ&pg=PA217</a>. [Accessed Oct. 11, 2019].</p>
<p>Robert Harley, <em>Mind: A Quarterly Review of Psychology and Philosophy</em>, 1879. Available: <a href="https://books.google.com/books?id=JBbkAAAAMAAJ&pg=PA201">https://books.google.com/books?id=JBbkAAAAMAAJ&pg=PA201</a>. [Accessed Oct. 11, 2019].</p>
